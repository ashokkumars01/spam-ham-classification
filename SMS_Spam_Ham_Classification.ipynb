{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Mon Sep 13 20:00:20 2021\\n\\n@author: Ashok Kumar S\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Sep 13 20:00:20 2021\n",
    "\n",
    "@author: Ashok Kumar S\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from logger_app import logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    logging.info(\"Importing Required Dependencies\")\n",
    "    import pandas as pd\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.ensemble import AdaBoostClassifier\n",
    "    from sklearn.ensemble import ExtraTreesClassifier\n",
    "    from sklearn.ensemble import GradientBoostingClassifier\n",
    "    from sklearn.svm import LinearSVC\n",
    "    from sklearn.svm import SVC\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.tree import ExtraTreeClassifier\n",
    "    from xgboost import XGBClassifier\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import numpy as np\n",
    "    import mysql.connector\n",
    "    import pickle\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    logging.exception(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the data from MySQL Database\n",
    "## Connecting a Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class database:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def connect_database():\n",
    "    \n",
    "        try:\n",
    "            logging.info(\"Connecting a Database\")\n",
    "            mydb = mysql.connector.connect(\n",
    "                    host = \"localhost\",\n",
    "                    user = \"root\",\n",
    "                    passwd = \"********\",# Give your database password\n",
    "                    database = \"spam_ham\")\n",
    "            return mydb\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.exception(e)\n",
    "            \n",
    "        \n",
    "mydb = database.connect_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class readdata:\n",
    "    \n",
    "    def __init__(self, db):\n",
    "        self.db = db\n",
    "        \n",
    "    def read_df(self):\n",
    "    \n",
    "        try:\n",
    "            logging.info(\"Reading the Data from MySQL\")\n",
    "            df = pd.read_sql(\"SELECT * FROM data\", con=self.db)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.exception(e)\n",
    "\n",
    "obj = readdata(mydb)\n",
    "df = obj.read_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6606 entries, 0 to 6605\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   Label    6606 non-null   object\n",
      " 1   Message  6606 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 103.3+ KB\n",
      "None\n",
      "Label      0\n",
      "Message    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    logging.info(\"Exploratory Data Analysis\")\n",
    "    info = df.info()\n",
    "\n",
    "    null = df.isnull().sum()\n",
    "\n",
    "    print(info)\n",
    "    print(null)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    logging.exception(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replacing a value ham as 0 and spam as 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class value:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def replace_val():\n",
    "    \n",
    "        try:\n",
    "            logging.info(\"Replacing a value with ham as 0 and spam as 1\")\n",
    "            df.replace({\"ham\":0, \"spam\":1}, inplace=True)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.exception(e)\n",
    "\n",
    "df = value.replace_val() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting histogram of Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class plot:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def hist_plot():\n",
    "        try:\n",
    "            logging.info(\"Plotting histogram\")\n",
    "            plt.hist(df['Label'],rwidth=0.95, color='g')\n",
    "            plt.xlabel(\"Sapm & Ham\")\n",
    "            plt.ylabel(\"Frequency\")\n",
    "            plt.title(\"Label\")\n",
    "            plt.show()\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.exception(e)\n",
    "        \n",
    "plot.hist_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Independent and Dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class variables:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def ind_dep():\n",
    "    \n",
    "        try:\n",
    "            logging.info(\"Independent and Dependent variables\")\n",
    "            X = df['Message']\n",
    "            Y = df['Label']\n",
    "            return X, Y\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.exception(e)\n",
    "\n",
    "X, Y = variables.ind_dep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Feature With CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "class feature:\n",
    "    \n",
    "    def __init__(self, X):\n",
    "        self.X = X\n",
    "        \n",
    "    def count_vector(self):\n",
    "    \n",
    "        try:\n",
    "            logging.info(\"Extract Feature With CountVectorizer\")\n",
    "            cv = CountVectorizer()\n",
    "            X = cv.fit_transform(self.X)\n",
    "            return X, cv\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.exception(e)\n",
    "        \n",
    "obj = feature(X)  \n",
    "X, cv = obj.count_vector()\n",
    "\n",
    "print(X.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumping Extracted features to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class file:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def dump():\n",
    "        try:\n",
    "            logging.info(\"Dumping Extracted features to pickle file\")\n",
    "            pickle.dump(cv, open(r'C:\\Users\\prash\\Desktop\\data\\SMS_Spam_Ham_Classification\\transform.pkl','wb'))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.exception(e)\n",
    "\n",
    "file.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data into Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class traintest:\n",
    "    \n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        \n",
    "    def data_split(self):\n",
    "        try:\n",
    "            logging.info(\"Splitting the data into Train and Test\")\n",
    "            X_train, X_test, Y_train, Y_test = train_test_split(self.X, self.Y, test_size=0.20, random_state=0)\n",
    "            return  X_train, X_test, Y_train, Y_test\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.exception(e)\n",
    "    \n",
    "obj = traintest(X, Y)\n",
    "X_train, X_test, Y_train, Y_test = obj.data_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "2584    0\n",
      "5530    0\n",
      "1526    0\n",
      "3784    0\n",
      "4357    0\n",
      "       ..\n",
      "4931    1\n",
      "3264    0\n",
      "1653    0\n",
      "2607    0\n",
      "2732    0\n",
      "Name: Label, Length: 5284, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X_train.toarray())\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB\n",
      "0.981089258698941\n",
      "[[1127   13]\n",
      " [  12  170]]\n",
      "0.981089258698941\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1140\n",
      "           1       0.93      0.93      0.93       182\n",
      "\n",
      "    accuracy                           0.98      1322\n",
      "   macro avg       0.96      0.96      0.96      1322\n",
      "weighted avg       0.98      0.98      0.98      1322\n",
      "\n",
      "LogisticRegression\n",
      "0.9871406959152799\n",
      "[[1140    0]\n",
      " [  17  165]]\n",
      "0.9871406959152799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1140\n",
      "           1       1.00      0.91      0.95       182\n",
      "\n",
      "    accuracy                           0.99      1322\n",
      "   macro avg       0.99      0.95      0.97      1322\n",
      "weighted avg       0.99      0.99      0.99      1322\n",
      "\n",
      "AdaBoostClassifier\n",
      "0.972768532526475\n",
      "[[1132    8]\n",
      " [  28  154]]\n",
      "0.972768532526475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      1140\n",
      "           1       0.95      0.85      0.90       182\n",
      "\n",
      "    accuracy                           0.97      1322\n",
      "   macro avg       0.96      0.92      0.94      1322\n",
      "weighted avg       0.97      0.97      0.97      1322\n",
      "\n",
      "ExtraTreesClassifier\n",
      "0.9878971255673222\n",
      "[[1139    1]\n",
      " [  15  167]]\n",
      "0.9878971255673222\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1140\n",
      "           1       0.99      0.92      0.95       182\n",
      "\n",
      "    accuracy                           0.99      1322\n",
      "   macro avg       0.99      0.96      0.97      1322\n",
      "weighted avg       0.99      0.99      0.99      1322\n",
      "\n",
      "GradientBoostingClassifier\n",
      "0.9795763993948563\n",
      "[[1140    0]\n",
      " [  27  155]]\n",
      "0.9795763993948563\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      1140\n",
      "           1       1.00      0.85      0.92       182\n",
      "\n",
      "    accuracy                           0.98      1322\n",
      "   macro avg       0.99      0.93      0.95      1322\n",
      "weighted avg       0.98      0.98      0.98      1322\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prash\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:06:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBClassifier\n",
      "0.9841149773071104\n",
      "[[1136    4]\n",
      " [  17  165]]\n",
      "0.9841149773071104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      1140\n",
      "           1       0.98      0.91      0.94       182\n",
      "\n",
      "    accuracy                           0.98      1322\n",
      "   macro avg       0.98      0.95      0.97      1322\n",
      "weighted avg       0.98      0.98      0.98      1322\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class model:\n",
    "    \n",
    "    def __init__(self, X_train, X_test, Y_train, Y_test):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.Y_train = Y_train\n",
    "        self.Y_test = Y_test\n",
    "        \n",
    "    def naive_bayes(self):\n",
    "        try:\n",
    "            logging.info(\"Fitting the Model Using MultinomialNB\")\n",
    "            ## Fitting the Model Using MultinomialNB\n",
    "            NB = MultinomialNB()\n",
    "            NB.fit(self.X_train, self.Y_train)\n",
    "            YNB_pred = NB.predict(self.X_test)\n",
    "            print(\"MultinomialNB\")\n",
    "            print(NB.score(self.X_test, self.Y_test))\n",
    "            print(confusion_matrix(self.Y_test, YNB_pred))\n",
    "            print(accuracy_score(self.Y_test, YNB_pred))\n",
    "            print(classification_report(self.Y_test, YNB_pred))\n",
    "            return YNB_pred, NB\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.exception(e)\n",
    "    \n",
    "    def logistic_regression(self):\n",
    "        try:\n",
    "            logging.info(\"Fitting the Model Using LogisticRegression\")\n",
    "            ## Fitting the Model Using LogisticRegression\n",
    "            LR = LogisticRegression()\n",
    "            LR.fit(self.X_train, self.Y_train)\n",
    "            YLR_pred = LR.predict(self.X_test)\n",
    "            print(\"LogisticRegression\")\n",
    "            print(LR.score(self.X_test, self.Y_test))\n",
    "            print(confusion_matrix(self.Y_test, YLR_pred))\n",
    "            print(accuracy_score(self.Y_test, YLR_pred))\n",
    "            print(classification_report(self.Y_test, YLR_pred))\n",
    "            return YLR_pred, LR\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.exception(e)\n",
    "    \n",
    "    def ada_boost(self):\n",
    "        try:\n",
    "            logging.info(\"Fitting the Model Using AdaBoostClassifier\")\n",
    "            ## Fitting the Model Using AdaBoostClassifier\n",
    "            ABC = AdaBoostClassifier()\n",
    "            ABC.fit(self.X_train, self.Y_train)\n",
    "            YABC_pred = ABC.predict(self.X_test)\n",
    "            print(\"AdaBoostClassifier\")\n",
    "            print(ABC.score(self.X_test, self.Y_test))\n",
    "            print(confusion_matrix(self.Y_test, YABC_pred))\n",
    "            print(accuracy_score(self.Y_test, YABC_pred))\n",
    "            print(classification_report(self.Y_test, YABC_pred))\n",
    "            return YABC_pred, ABC\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.exception(e)\n",
    "    \n",
    "    def extra_tree(self):\n",
    "        try:\n",
    "            logging.info(\"Fitting the Model Using ExtraTreesClassifier\")\n",
    "            ## Fitting the Model Using ExtraTreesClassifier\n",
    "            ETC = ExtraTreesClassifier()\n",
    "            ETC.fit(self.X_train, self.Y_train)\n",
    "            YETC_pred = ETC.predict(self.X_test)\n",
    "            print(\"ExtraTreesClassifier\")\n",
    "            print(ETC.score(self.X_test, self.Y_test))\n",
    "            print(confusion_matrix(self.Y_test, YETC_pred))\n",
    "            print(accuracy_score(self.Y_test, YETC_pred))\n",
    "            print(classification_report(self.Y_test, YETC_pred))\n",
    "            return YETC_pred, ETC\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.exception(e)\n",
    "    \n",
    "    def gradient_boost(self):\n",
    "        try:\n",
    "            logging.info(\"Fitting the Model Using GradientBoostingClassifier\")\n",
    "            ## Fitting the Model Using GradientBoostingClassifier\n",
    "            GBC = GradientBoostingClassifier()\n",
    "            GBC.fit(self.X_train, self.Y_train)\n",
    "            YGBC_pred = GBC.predict(self.X_test)\n",
    "            print(\"GradientBoostingClassifier\")\n",
    "            print(GBC.score(self.X_test, self.Y_test))\n",
    "            print(confusion_matrix(self.Y_test, YGBC_pred))\n",
    "            print(accuracy_score(self.Y_test, YGBC_pred))\n",
    "            print(classification_report(self.Y_test, YGBC_pred))\n",
    "            return YGBC_pred, GBC\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.exception(e)\n",
    "    \n",
    "    def xgboost(self):\n",
    "        try:\n",
    "            logging.info(\"Fitting the Model Using XGBClassifier\")\n",
    "            ## Fitting the Model Using XGBClassifier\n",
    "            xgb = XGBClassifier()\n",
    "            xgb.fit(self.X_train, self.Y_train)\n",
    "            Yxgb_pred = xgb.predict(self.X_test)\n",
    "            print(\"XGBClassifier\")\n",
    "            print(xgb.score(self.X_test, self.Y_test))\n",
    "            print(confusion_matrix(self.Y_test, Yxgb_pred))\n",
    "            print(accuracy_score(self.Y_test, Yxgb_pred))\n",
    "            print(classification_report(self.Y_test, Yxgb_pred))\n",
    "            return Yxgb_pred, xgb\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.exception(e)\n",
    "    \n",
    "        \n",
    "obj = model(X_train, X_test, Y_train, Y_test)\n",
    "YNB_pred, NB = obj.naive_bayes()\n",
    "YLR_pred, LR = obj.logistic_regression()\n",
    "YABC_pred, ABC = obj.ada_boost()\n",
    "YETC_pred, ETC = obj.extra_tree()\n",
    "YGBC_pred, GBC = obj.gradient_boost()\n",
    "Yxgb_pred, xgb = obj.xgboost()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dumping the Model to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pkl:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def spam_ham():\n",
    "        try:\n",
    "            logging.info(\"Dumping the Model to pickle file\")\n",
    "            pickle.dump(LR, open(r'C:\\Users\\prash\\Desktop\\data\\SMS_Spam_Ham_Classification\\Logistic_Regression.pkl','wb'))\n",
    "            pickle.dump(NB, open(r'C:\\Users\\prash\\Desktop\\data\\SMS_Spam_Ham_Classification\\Naive_Bayes.pkl','wb'))\n",
    "            pickle.dump(ABC, open(r'C:\\Users\\prash\\Desktop\\data\\SMS_Spam_Ham_Classification\\Adaboost_classifier.pkl','wb'))\n",
    "            pickle.dump(ETC, open(r'C:\\Users\\prash\\Desktop\\data\\SMS_Spam_Ham_Classification\\Extratrees_classifier.pkl','wb'))\n",
    "            pickle.dump(GBC, open(r'C:\\Users\\prash\\Desktop\\data\\SMS_Spam_Ham_Classification\\Gradientboost_classifier.pkl','wb'))\n",
    "            pickle.dump(xgb, open(r'C:\\Users\\prash\\Desktop\\data\\SMS_Spam_Ham_Classification\\XGBoost_classifier.pkl','wb'))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.exception(e)\n",
    "\n",
    "pkl.spam_ham()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Prediction is Spam\n"
     ]
    }
   ],
   "source": [
    "class pred:\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def prediction(self):\n",
    "        try:\n",
    "            logging.info(\"Prediction on user data\")\n",
    "            data = cv.transform(self.data)\n",
    "            y_pred = LR.predict(data)\n",
    "            print(y_pred)\n",
    "            if y_pred == 0:\n",
    "                print(\"Prediction is Ham\")\n",
    "            else:\n",
    "                print(\"Prediction is Spam\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.exception(e)\n",
    "            \n",
    "data = [\" +123 Congratulations - in this week's competition draw u have won the Â£1450 prize to claim just call 09050002311 b4280703. T&Cs/stop SMS 08718727868. Over 18 only 150ppm \"]\n",
    "obj = pred(data)\n",
    "obj.prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Pickle file and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "Prediction is Ham\n"
     ]
    }
   ],
   "source": [
    "class load_model:\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    def pred(self):\n",
    "        try:\n",
    "            logging.info(\"Loading pickle file and Prediction\")\n",
    "            model = pickle.load(open(r'C:\\Users\\prash\\Desktop\\data\\SMS_Spam_Ham_Classification\\Extratrees_classifier.pkl','rb'))\n",
    "            cv = pickle.load(open(r'C:\\Users\\prash\\Desktop\\data\\SMS_Spam_Ham_Classification\\transform.pkl','rb'))\n",
    "            data = cv.transform(self.data)\n",
    "            y_pred = LR.predict(data)\n",
    "            print(y_pred)\n",
    "            if y_pred == 0:\n",
    "                print(\"Prediction is Ham\")\n",
    "            else:\n",
    "                print(\"Prediction is Spam\")\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            logging.exception(e)\n",
    "            \n",
    "data = [\"&lt;#&gt;  am I think? Should say on syllabus\"]\n",
    "obj = load_model(data)\n",
    "obj.pred()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
